{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, x, y, outdir, tag, title, timing=None, smooth=1):\n",
    "    if smooth > 1:\n",
    "        \"\"\"\n",
    "        smooth data with moving window average.\n",
    "        that is,\n",
    "            smoothed_y[t] = average(y[t-k], y[t-k+1], ..., y[t+k-1], y[t+k])\n",
    "        where the \"smooth\" param is width of that window (2k+1)\n",
    "        \"\"\"\n",
    "        y = np.ones(smooth)\n",
    "        for datum in data:\n",
    "            x = np.asarray(datum[y])\n",
    "            z = np.ones(len(x))\n",
    "            smoothed_x = np.convolve(x,y,'same') / np.convolve(z,y,'same')\n",
    "            datum[y] = smoothed_x\n",
    "            \n",
    "    if isinstance(data, list):\n",
    "        data = pd.concat(data, ignore_index=True)\n",
    "        if timing:\n",
    "            data = data[data.timing == timing].drop('timing', axis=1)\n",
    "\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "    sns.set_palette('Set2') # or husl\n",
    "    if 'timing' in data.columns:\n",
    "        sns.lineplot(x=x, y=y, ax=ax, data=data, hue=tag, style='timing')\n",
    "    else:\n",
    "        sns.lineplot(x=x, y=y, ax=ax, data=data, hue=tag)\n",
    "    ax.grid(True, alpha=0.8, linestyle=':')\n",
    "    ax.legend(loc='best').set_draggable(True)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    if timing:\n",
    "        title = f'{title}-{timing}'\n",
    "    outpath = f'{outdir}/{title}.png'\n",
    "    ax.set_title(title)\n",
    "    fig.savefig(outpath)\n",
    "    fig.show()\n",
    "    print(f'Plot Path: {outpath}')\n",
    "\n",
    "def get_datasets(files, tag, condition=None):\n",
    "    unit = 0\n",
    "    datasets = []\n",
    "    for f in files:\n",
    "        assert f.endswith('log.txt')\n",
    "        data = pd.read_csv(f, sep='\\t')\n",
    "\n",
    "        data.insert(len(data.columns), tag, condition)\n",
    "\n",
    "        datasets.append(data)\n",
    "        unit +=1\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup(obj):\n",
    "    def _getattr(self, name):\n",
    "        if name.startswith('_'):\n",
    "            raise AttributeError(\"attempted to get missing private attribute '{}'\".format(name))\n",
    "        return getattr(self.d, name)\n",
    "    obj.d = dict()\n",
    "    for a in dir(obj.d):\n",
    "        if not a.startswith('_'):\n",
    "            setattr(obj, a, getattr(obj.d, a))\n",
    "#     setattr(obj, '__getattribute__', obj.d.__getattribute__)\n",
    "\n",
    "    \n",
    "class A:\n",
    "    def __init__(self):\n",
    "        self.d = []\n",
    "\n",
    "\n",
    "a = A()\n",
    "setup(a)\n",
    "a.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f() got multiple values for argument 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-744ceddd287f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: f() got multiple values for argument 'a'"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "def f(a, b, c, d):\n",
    "    print(a, b, c, d)\n",
    "\n",
    "g = functools.partial(f, 1, 2)\n",
    "g(3, 4, a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.209749 ,  8.690623 ,  5.6069465],\n",
       "        [ 9.360001 ,  5.378809 , 10.760001 ]], dtype=float32),\n",
       " array([[ 9.209749 ,  9.446628 ,  4.9402804],\n",
       "        [15.580001 ,  4.0454755, 16.946669 ]], dtype=float32))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def static_scan(fn, start, inputs, reverse=False):\n",
    "    \"\"\" Sequentially apply fn to inputs, with starting state start.\n",
    "    inputs are expected to be time-major, and the outputs of fn are expected\n",
    "    to have the same structure as start. \n",
    "    This function is equivalent to \n",
    "    tf.scan(\n",
    "        fn=fn\n",
    "        elems=inputs, \n",
    "        initializer=start,\n",
    "        parallel_iterations=1,\n",
    "        reverse=reverse\n",
    "    )\n",
    "    In practice, we find it's faster than tf.scan\n",
    "    \"\"\"\n",
    "    last = start\n",
    "    outputs = [[] for _ in tf.nest.flatten(start)]\n",
    "    indices = range(len(tf.nest.flatten(inputs)[0]))\n",
    "    if reverse:\n",
    "        indices = reversed(indices)\n",
    "    for index in indices:\n",
    "        # extract inputs at step index\n",
    "        inp = tf.nest.map_structure(lambda x: x[index], inputs)\n",
    "        last = fn(last, inp)\n",
    "        # distribute outputs\n",
    "        [o.append(l) for o, l in zip(outputs, tf.nest.flatten(last))]\n",
    "    if reverse:\n",
    "        outputs = [list(reversed(x)) for x in outputs]\n",
    "    outputs = [tf.stack(x) for x in outputs]\n",
    "    # reconstruct outputs to have the same structure as start\n",
    "    return tf.nest.pack_sequence_as(start, outputs)\n",
    "\n",
    "def v_trace(reward, value, next_value, pi, mu, discount, lambda_=1, \n",
    "        c_clip=1, rho_clip=1, rho_clip_pg=1, axis=0):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        discount = gamma * (1-done). \n",
    "        axis specifies the time dimension\n",
    "    \"\"\"\n",
    "#     assert_rank_and_shape_compatibility(\n",
    "#         [reward, value, next_value, pi, mu, discount])\n",
    "    \n",
    "    ratio = pi / mu\n",
    "    \n",
    "    # swap 'axis' with the 0-th dimension\n",
    "    dims = list(range(reward.shape.ndims))\n",
    "    dims = [axis] + dims[1:axis] + [0] + dims[axis + 1:]\n",
    "    if axis != 0:\n",
    "        reward = tf.transpose(reward, dims)\n",
    "        value = tf.transpose(value, dims)\n",
    "        next_value = tf.transpose(next_value, dims)\n",
    "        ratio = tf.transpose(ratio, dims)\n",
    "        discount = tf.transpose(discount, dims)\n",
    "    \n",
    "    clipped_c = ratio if c_clip is None else tf.minimum(ratio, c_clip)\n",
    "    clipped_rho = ratio if rho_clip is None else tf.minimum(ratio, rho_clip)\n",
    "    if lambda_ is not None and lambda_ != 1:\n",
    "        clipped_rho = lambda_ * clipped_rho\n",
    "\n",
    "    delta = clipped_rho * (reward + discount * next_value - value)\n",
    "    \n",
    "    initial_value = tf.zeros_like(delta[-1])\n",
    "\n",
    "    v_minus_V = static_scan(\n",
    "        lambda acc, x: x[0] + x[1] * x[2] * acc,\n",
    "        initial_value, (delta, discount, clipped_c),\n",
    "        reverse=True)\n",
    "    \n",
    "    vs = v_minus_V + value\n",
    "\n",
    "    next_vs = tf.concat([vs[1:], next_value[-1:]], axis=0)\n",
    "    clipped_rho_pg = ratio if rho_clip_pg is None else tf.minimum(ratio, rho_clip_pg)\n",
    "    adv = clipped_rho_pg * (reward + discount * next_vs - value)\n",
    "\n",
    "    if axis != 0:\n",
    "        vs = tf.transpose(vs, dims)\n",
    "        adv = tf.transpose(adv, dims)\n",
    "    \n",
    "    return vs, adv\n",
    "\n",
    "tf.nest.map_structure(lambda x: x.numpy(), v_trace(**tf.nest.map_structure(\n",
    "    lambda x: tf.convert_to_tensor(x, tf.float32), values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aptx4869/anaconda3/envs/drl/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling scan_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.scan(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.scan(fn, elems))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 9.209749 ,  8.690623 ,  5.6069465],\n",
       "        [ 9.360001 ,  5.378809 , 10.760001 ]], dtype=float32),\n",
       " array([[ 9.209749 ,  9.446628 ,  4.9402804],\n",
       "        [15.580001 ,  4.0454755, 16.946669 ]], dtype=float32))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vtrace_from_importance_weights(reward, value, next_value, pi, mu, discount, lambda_=1,\n",
    "    c_clip=1, rho_clip=1.0, rho_clip_pg=1.0,\n",
    "    name='vtrace_from_importance_weights'):\n",
    "\n",
    "    log_rhos = tf.convert_to_tensor(tf.math.log(pi/mu), dtype=tf.float32)\n",
    "    discounts = tf.convert_to_tensor(discount, dtype=tf.float32)\n",
    "    rewards = tf.convert_to_tensor(reward, dtype=tf.float32)\n",
    "    values = tf.convert_to_tensor(value, dtype=tf.float32)\n",
    "    bootstrap_value = tf.convert_to_tensor(next_value[-1], dtype=tf.float32)\n",
    "    if rho_clip is not None:\n",
    "        clip_rho_threshold = tf.convert_to_tensor(rho_clip, dtype=tf.float32)\n",
    "    if rho_clip_pg is not None:\n",
    "        clip_pg_rho_threshold = tf.convert_to_tensor(rho_clip_pg, dtype=tf.float32)\n",
    "\n",
    "    # Make sure tensor ranks are consistent.\n",
    "    rho_rank = log_rhos.shape.ndims  # Usually 2.\n",
    "    values.shape.assert_has_rank(rho_rank)\n",
    "    bootstrap_value.shape.assert_has_rank(rho_rank - 1)\n",
    "    discounts.shape.assert_has_rank(rho_rank)\n",
    "    rewards.shape.assert_has_rank(rho_rank)\n",
    "    if clip_rho_threshold is not None:\n",
    "        clip_rho_threshold.shape.assert_has_rank(0)\n",
    "    if clip_pg_rho_threshold is not None:\n",
    "        clip_pg_rho_threshold.shape.assert_has_rank(0)\n",
    "\n",
    "    rhos = tf.exp(log_rhos)\n",
    "    if clip_rho_threshold is not None:\n",
    "        clipped_rhos = tf.minimum(clip_rho_threshold, rhos, name='clipped_rhos')\n",
    "    else:\n",
    "        clipped_rhos = rhos\n",
    "\n",
    "    cs = tf.minimum(c_clip, rhos, name='cs')\n",
    "    # Append bootstrapped value to get [v1, ..., v_t+1]\n",
    "    values_t_plus_1 = tf.concat(\n",
    "        [values[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "    deltas = clipped_rhos * (rewards + discounts * values_t_plus_1 - values)\n",
    "\n",
    "    # Note that all sequences are reversed, computation starts from the back.\n",
    "    sequences = (\n",
    "        tf.reverse(discounts, axis=[0]),\n",
    "        tf.reverse(cs, axis=[0]),\n",
    "        tf.reverse(deltas, axis=[0]),\n",
    "    )\n",
    "    # V-trace vs are calculated through a scan from the back to the beginning\n",
    "    # of the given trajectory.\n",
    "    def scanfunc(acc, sequence_item):\n",
    "        discount_t, c_t, delta_t = sequence_item\n",
    "        return delta_t + discount_t * c_t * acc\n",
    "\n",
    "    initial_values = tf.zeros_like(bootstrap_value)\n",
    "    vs_minus_v_xs = tf.scan(\n",
    "        fn=scanfunc,\n",
    "        elems=sequences,\n",
    "        initializer=initial_values,\n",
    "        parallel_iterations=1,\n",
    "        back_prop=False,\n",
    "        name='scan')\n",
    "    # Reverse the results back to original order.\n",
    "    vs_minus_v_xs = tf.reverse(vs_minus_v_xs, [0], name='vs_minus_v_xs')\n",
    "\n",
    "    # Add V(x_s) to get v_s.\n",
    "    vs = tf.add(vs_minus_v_xs, values, name='vs')\n",
    "\n",
    "    # Advantage for policy gradient.\n",
    "    vs_t_plus_1 = tf.concat([\n",
    "        vs[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "    if clip_pg_rho_threshold is not None:\n",
    "        clipped_pg_rhos = tf.minimum(clip_pg_rho_threshold, rhos,\n",
    "                                   name='clipped_pg_rhos')\n",
    "    else:\n",
    "        clipped_pg_rhos = rhos\n",
    "    pg_advantages = (\n",
    "        clipped_pg_rhos * (rewards + discounts * vs_t_plus_1 - values))\n",
    "\n",
    "    # Make sure no gradients backpropagated through the returned values.\n",
    "    return tf.stop_gradient(vs), tf.stop_gradient(pg_advantages)\n",
    "\n",
    "tf.nest.map_structure(lambda x: x.numpy(), vtrace_from_importance_weights(**tf.nest.map_structure(\n",
    "    lambda x: tf.convert_to_tensor(x, tf.float32), values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4375,  0.4375])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[3, 0], [5, 1]])\n",
    "x = np.array([.5, .5])\n",
    "y = np.array([.75, .25])\n",
    "i = 0\n",
    "x * ((A @ y) - x @ A @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.28125,  0.28125])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[3, 5], [0, 1]])\n",
    "x = np.array([.5, .5])\n",
    "y = np.array([.75, .25])\n",
    "i = 1\n",
    "y * ((x @ B) - x @ B @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.7 ms ± 243 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.swapaxes(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ms ± 355 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "y = np.array(x)\n",
    "np.swapaxes(y, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class QMixer(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(QMixer, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        self.n_agents = args.n_agents\n",
    "        self.state_dim = int(np.prod(args.state_shape))\n",
    "\n",
    "        self.embed_dim = args.mixing_embed_dim\n",
    "\n",
    "        if getattr(args, \"hypernet_layers\", 1) == 1:\n",
    "            self.hyper_w_1 = nn.Linear(self.state_dim, self.embed_dim * self.n_agents)\n",
    "            self.hyper_w_final = nn.Linear(self.state_dim, self.embed_dim)\n",
    "        elif getattr(args, \"hypernet_layers\", 1) == 2:\n",
    "            hypernet_embed = self.args.hypernet_embed\n",
    "            self.hyper_w_1 = nn.Sequential(nn.Linear(self.state_dim, hypernet_embed),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(hypernet_embed, self.embed_dim * self.n_agents))\n",
    "            self.hyper_w_final = nn.Sequential(nn.Linear(self.state_dim, hypernet_embed),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.Linear(hypernet_embed, self.embed_dim))\n",
    "        elif getattr(args, \"hypernet_layers\", 1) > 2:\n",
    "            raise Exception(\"Sorry >2 hypernet layers is not implemented!\")\n",
    "        else:\n",
    "            raise Exception(\"Error setting number of hypernet layers.\")\n",
    "\n",
    "        # State dependent bias for hidden layer\n",
    "        self.hyper_b_1 = nn.Linear(self.state_dim, self.embed_dim)\n",
    "\n",
    "        # V(s) instead of a bias for the last layerst\n",
    "        self.V = nn.Sequential(nn.Linear(self.state_dim, self.embed_dim),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(self.embed_dim, 1))\n",
    "\n",
    "    def forward(self, agent_qs, states):\n",
    "        bs = agent_qs.size(0)\n",
    "        states = states.reshape(-1, self.state_dim)\n",
    "        agent_qs = agent_qs.view(-1, 1, self.n_agents)\n",
    "        # First layer\n",
    "        w1 = th.abs(self.hyper_w_1(states))\n",
    "        b1 = self.hyper_b_1(states)\n",
    "        w1 = w1.view(-1, self.n_agents, self.embed_dim)\n",
    "        b1 = b1.view(-1, 1, self.embed_dim)\n",
    "        hidden = F.elu(th.bmm(agent_qs, w1) + b1)\n",
    "        # Second layer\n",
    "        w_final = th.abs(self.hyper_w_final(states))\n",
    "        w_final = w_final.view(-1, self.embed_dim, 1)\n",
    "        # State-dependent bias\n",
    "        v = self.V(states).view(-1, 1, 1)\n",
    "        # Compute final output\n",
    "        y = th.bmm(hidden, w_final) + v\n",
    "        # Reshape and return\n",
    "        q_tot = y.view(bs, -1, 1)\n",
    "        return q_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.state_shape = (3, 4)\n",
    "        self.n_agents = 3\n",
    "        self.mixing_embed_dim = 9\n",
    "args = Args()\n",
    "qmix = QMixer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[ 1.5370384 , -0.09481981, -1.6808445 ,  1.0012864 ],\n",
       "       [ 2.5243452 , -1.909442  ,  0.69922054, -1.9831874 ],\n",
       "       [ 1.7966232 ,  1.1815207 , -2.9724448 , -2.1147866 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 3\n",
    "A = 2\n",
    "H = 4\n",
    "x = tf.random.normal((B, A))\n",
    "y = tf.random.normal((B, A, H))\n",
    "tf.einsum('ba,bah->bh', x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5370384 , -0.09481981, -1.6808445 ,  1.0012864 ],\n",
       "       [ 2.5243452 , -1.909442  ,  0.69922054, -1.9831874 ],\n",
       "       [ 1.7966232 ,  1.1815207 , -2.9724448 , -2.1147866 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xe = tf.expand_dims(x, 1)\n",
    "np.squeeze(tf.matmul(xe, y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-5dd8c1bc2428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "np.shape(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def nearest_cluster_idx(centroids, feat):\n",
    "    return np.argmin(np.mean((centroids - feat[None])**2, -1))\n",
    "\n",
    "def kmean(data, k, n):\n",
    "    max_feat = np.max(data, 0)\n",
    "    min_feat = np.min(data, 0)\n",
    "    step = data.shape[0] // k\n",
    "    centroids = data[:k]\n",
    "    \n",
    "    for _ in range(n):\n",
    "        feats = [[] for _ in range(k)]\n",
    "        for feat in data:\n",
    "            i = nearest_cluster_idx(centroids, feat)\n",
    "            feats[i].append(feat)\n",
    "        centroids = np.array([np.mean(fs, axis=0) for fs in feats])\n",
    "    return centroids\n",
    "\n",
    "data = np.concatenate([np.random.normal(i, 1, (10, 2)) for i in range(10)], 0)\n",
    "np.random.shuffle(data)\n",
    "centroids = kmean(data, 10, 100)\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[-1.0000000e+10, -4.3082278e-02,  7.8758178e-03, -1.0000000e+10,\n",
       "        -5.6906357e-02],\n",
       "       [ 1.9747494e-03, -1.0000000e+10, -1.0000000e+10, -1.0000000e+10,\n",
       "        -1.0000000e+10]], dtype=float32)>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_e = tf.expand_dims(b, 1)\n",
    "a_t = tf.transpose(a, [0, 2, 1])\n",
    "x = tf.squeeze(tf.matmul(b_e, a_t))\n",
    "tf.where(x == 0, -1e10, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156672000"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "process = pszutil.Process()\n",
    "process.memory_info().rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b'}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a': 10, 'b': 20}\n",
    "set(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 4), dtype=float32, numpy=\n",
       "array([[[[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.zeros((2, 2, 2, 4))\n",
    "pool = tf.ones((2, 2, 1, 4))\n",
    "n = x.shape[-1]\n",
    "feat = tf.reshape(tf.range(n, dtype=tf.int32), (1, 1, 1, -1))\n",
    "x = tf.where(feat < tf.cast(n * .25, tf.int32), pool, x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
