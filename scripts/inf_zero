#!/bin/bash

export PYTHONPATH=.

algos=(
    happo_mb
)
suite=$1
envs=(
    # Ant_8x1
    # HalfCheetah_6x1
    # Walker2d_6x1
    # Ant_4x2
    # HalfCheetah_3x2
    # Walker2d_3x2
    Ant_2x4
    HalfCheetah_2x3
    Walker2d_2x3
)
# e=${suite}
configs=(
    "${suite}"
)
# configs=$envs
args1=(50 50 100 100 150 150)
args2=(
    256
    # .9,.09,.009,.0009,.00009,.00001 
    # .00001,.9,.09,.009,.0009,.00009 
    # .00009,.00001,.9,.09,.009,.0009 
    # .0009,.00009,.00001,.9,.09,.009 
    # .009,.0009,.00009,.00001,.9,.09 
    # .09,.009,.0009,.00009,.00001,.9 
    # .005,.045,.45,.005,.045,.45 
    # .166,.167,.167,.166,.167,.167
    # .45,.045,.005,.45,.045,.005 
    # .9,.09,.01
    # .01,.9,.09
    # .09,.01,.9
    # .33,.33,.34
    # .9,.1
    # .1,.9
    # .5,.5
    # .9,.1
    # .1,.9
    # .5,.5
)
args3=(1 10)
date=$(date +"%m%d")
# date="0204"
info=""
ld="${suite}-logs"
# gpus=$(nvidia-smi -L | wc -l)
# for x in $(seq 1 1); do
#     shift
# done

if [ -z "$info" ]; then
    n=$date
else
    n="$date-$info"
fi

le=${#envs[@]}
idx=$(($INF_MAC_NODE_RANK % $le))
e=${envs[$idx]}
env="${suite}-${e}"
lc=${#configs[@]}
idx=$(($INF_MAC_NODE_RANK % $lc))
config=${configs[$idx]}
la=${#algos[@]}
idx=$(($INF_MAC_NODE_RANK % $la))
a=${algos[$idx]}
la1=${#args1[@]}
idx=$(($INF_MAC_NODE_RANK % $la1))
a1=${args1[$idx]}
la2=${#args2[@]}
idx=$(($INF_MAC_NODE_RANK % $la2))
a2=${args2[$idx]}
la3=${#args3[@]}
idx=$(($INF_MAC_NODE_RANK % $la3))
a3=${args3[$idx]}
# kws=$@

commands=()
kws="n_epochs=$a1 batch_size=$a2 sample_size=$a3"
for e in "${envs[@]}"; do
    env="${suite}-${e}"
    for s in {0..4}; do
        py_script="python run/train.py -a ${a} ${a} dynamics -e $env -c $config -ld $ld -n $n -s $s -kw $kws -ki 2"
        commands+=("$py_script")
        echo $py_script
        # eval $py_script
    done
done
# echo ${commands[@]}s
lc=${#commands[@]}
p=$((lc / le))
# echo $p
printf '%s\n' "${commands[@]}" | xargs -I COMMAND -P 16 -L 1 bash -c COMMAND 
# nn="${n}_so"
# for s in {0..5}; do
#     py_script="python run/train.py -a ${a} -e $env -c ${config}_so -ld $ld -n $nn -s $s -na $na -kw $kws &"
#     echo $py_script
#     eval $py_script
# done
# done
# for config in "${configs[@]}"; do
#     for s in {0..5}; do
#         # echo $kws
#         if [[ "$OSTYPE" == 'linux-gnu'* ]]; then
#             gpus=$(nvidia-smi -L | wc -l)
#             gpu=$(($i % $gpus))
#             py_script="python run/train.py -a ${a} -e $env -c $config -ld $ld -n $n -s $s --gpu $gpu -na $na -kw $kws &"
#         else
#             py_script="python run/train.py -a ${a} -e $env -c $config -ld $ld -n $n -s $s -na $na -kw $kws &"
#         fi
#         echo $py_script
#         eval $py_script
#         ((i=(i+1) ))
#     done
# done
# wait
echo "Script completed"
# for e in "${envs[@]}"; do
# le=${#envs[@]}
# idx=$(($INF_MAC_NODE_RANK % $le))
# e=${envs[$idx]}
# lc=${#configs[@]}
# idx=$(($INF_MAC_NODE_RANK % $lc))
# config=${configs[$idx]}
# la1=${#args1[@]}
# idx=$(($INF_MAC_NODE_RANK % $la1))
# a1=${args1[$idx]}
# la2=${#args2[@]}
# idx=$(($INF_MAC_NODE_RANK % $la2))
# a2=${args2[$idx]}
# la3=${#args3[@]}
# idx=$(($INF_MAC_NODE_RANK % $la3))
# a3=${args3[$idx]}
# if [[ "${suite}" == "mpe" ]]; then
#     na=3
# else
#     na=2
# fi
# for a in "${algos[@]}"; do
#     for s in {0..9}; do
#         kws="n_lookahead_steps=$a1"
#         # echo $kws
#         env="${suite}-${e}"
#         if [[ "$OSTYPE" == 'linux-gnu'* ]]; then
#             gpu=$(($i % $gpus))
#             py_script="python run/train.py -a ${a} -e $env -c $config -ld $ld -n $n -s $s --gpu $gpu -na $na -kw $kws &"
#         else
#             py_script="python run/train.py -a ${a} -e $env -c $config -ld $ld -n $n -s $s -na $na -kw $kws &"
#         fi
#         echo $py_script
#         eval $py_script
#         ((i=(i+1) ))
#     done
#     # wait
# done
# wait
# echo "Script completed"